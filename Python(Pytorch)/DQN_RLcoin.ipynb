{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Q_net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Q_net, self).__init__()\n",
    "        self.fc1 = nn.Linear(2,20)\n",
    "        self.fc2 = nn.Linear(3,2)\n",
    "        self.fc5 = nn.Linear(20,3)\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.fc1(x),0.1, True)\n",
    "        x = self.fc5(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, device, replay, optimizer):\n",
    "    gamma=0.9\n",
    "    losses=list()\n",
    "    \n",
    "    for i, (S_t,A_t,R_tp,S_tp) in enumerate(replay):\n",
    "        # processing replay    \n",
    "        #if j==0:\n",
    "            #print('S_t,A_t,R_tp,S_tp:',S_t,A_t,R_tp,S_tp)\n",
    "        _,V=e_greedy(S_tp,e=0)\n",
    "        _,target_new=e_greedy(S_t,e=0)\n",
    "        \n",
    "        act_ind=np.int32(A_t.cpu().numpy()-1)\n",
    "        \n",
    "        if torch.all(torch.eq(target_new,V)):\n",
    "            r=R_tp\n",
    "        else:\n",
    "            r=R_tp+gamma*V.max()\n",
    "        target_new[act_ind]=R_tp\n",
    "        target_new=target_new.to(device)\n",
    "        if i==0:\n",
    "            target=target_new\n",
    "            s=torch.tensor(S_t,dtype=torch.float32).cuda()\n",
    "            S=Variable(s,requires_grad=True)\n",
    "            data=S\n",
    "        else:\n",
    "            s=torch.tensor(S_t,dtype=torch.float32).cuda()\n",
    "            S=Variable(s,requires_grad=True)\n",
    "            data=torch.cat((data,S))\n",
    "            target=torch.cat((target,target_new))\n",
    "    target=target.view(i+1,3)\n",
    "    data=data.view(i+1,2)\n",
    "    if i+1>30:\n",
    "        #print('Batch Size',30)\n",
    "        target=target[-31:-1,:]\n",
    "        data=data[-31:-1,:]\n",
    "    #else:\n",
    "        #print('Batch Size',i+1)\n",
    "    model.train()\n",
    "    for j in range(1):\n",
    "        # train        \n",
    "        optimizer.zero_grad()\n",
    "        output = model.forward(data)\n",
    "        loss = F.mse_loss(output, target)\n",
    "        #print(loss)\n",
    "        losses.append(loss.item())\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "    \n",
    "    return losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup(lr=1e-2):\n",
    "    device = torch.cuda.current_device()\n",
    "    model = Q_net().to(device)\n",
    "    optimizer = optim.RMSprop(model.parameters(), lr=lr)\n",
    "    return device, model, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(d=10):\n",
    "    d=d+1\n",
    "    V_1=np.zeros([d,d])\n",
    "    V_2=np.zeros([d,d])\n",
    "    V_3=np.zeros([d,d])\n",
    "    for i in range(d):\n",
    "        for j in range(d):\n",
    "            a,V=e_greedy([i,j],e=0)\n",
    "            V_1[i,j]=V[0].item()\n",
    "            V_2[i,j]=V[1].item()\n",
    "            V_3[i,j]=V[2].item()\n",
    "    maX=np.max([np.max(V_1),np.max(V_2),np.max(V_3)])\n",
    "    Min=np.min([np.min(V_1),np.min(V_2),np.min(V_3)])\n",
    "    \n",
    "    #V_1=(V_1-Min)/(maX-Min)\n",
    "    #V_2=(V_2-Min)/(maX-Min)\n",
    "    #V_3=(V_3-Min)/(maX-Min)\n",
    "    \n",
    "    ax1=plt.subplot(2,2,1)    \n",
    "    plt.imshow(V_1,cmap=plt.get_cmap('viridis'),\n",
    "               vmin=Min, vmax=maX)   \n",
    "    ax2=plt.subplot(2,2,2)    \n",
    "    plt.imshow(V_2,cmap=plt.get_cmap('viridis'),\n",
    "               vmin=Min, vmax=maX)\n",
    "    ax3=plt.subplot(2,2,3)    \n",
    "    plt.imshow(V_3,cmap=plt.get_cmap('viridis'), \n",
    "               vmin=Min, vmax=maX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def e_greedy(S,e=1e-2):\n",
    "    s=torch.tensor(S,dtype=torch.float32)\n",
    "    S=Variable(s,requires_grad=True)\n",
    "    S=S.to(device)\n",
    "    V=model.forward(S)\n",
    "    v,ind = V.max(0)\n",
    "    aa=[i for i, j in enumerate(V) if j == v]\n",
    "    a=0\n",
    "    if np.random.rand(1)<=1-e:\n",
    "        if len(aa)==1:\n",
    "            a=ind+1\n",
    "        elif 0 in aa:\n",
    "            a=1\n",
    "        else:\n",
    "            a=ind+1\n",
    "    else:\n",
    "        a=np.random.randint(1,4)\n",
    "    a=torch.tensor(a,dtype=torch.float32)\n",
    "    if np.isnan(a):\n",
    "        print('NNNNNNNAn')\n",
    "    return a,V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Environment(f=1/3,R_plus=1,R_minus=20,e=1e-2,max_toss=8000):\n",
    "    model.eval()\n",
    "    S_0=np.array([0,0])\n",
    "    replay=[]\n",
    "    coin=np.random.randint(2,4)\n",
    "    #print('coin',coin)\n",
    "    if coin==3:\n",
    "        S_list=S_0\n",
    "        i=0\n",
    "        while i<max_toss:\n",
    "            if i==0:\n",
    "                a,_=e_greedy(S_list,e=e)\n",
    "            else:\n",
    "                a,_=e_greedy(S_list[-1,:],e=e)\n",
    "            #print(a)\n",
    "            i=i+1\n",
    "            if a!=1:\n",
    "                if a==coin:\n",
    "                    Reward=R_plus/max((len(S_list)-1),1)\n",
    "                else:\n",
    "                    Reward=-R_minus/max((len(S_list)-1),1)\n",
    "                #print(S_list)\n",
    "                if S_list.ndim==1:\n",
    "                    replay.append([S_list,a,Reward,S_list])\n",
    "                else:\n",
    "                    replay.append([S_list[-1,:],a,Reward,S_list[-1,:]])\n",
    "                break\n",
    "            else:\n",
    "                #rint(S_list)\n",
    "                if np.random.rand(1)<1-f:\n",
    "                    S_list=np.vstack((S_list,np.array([0,1])))\n",
    "                    S_list[-1,:]=S_list[-1,:]+S_list[-2,:]\n",
    "                else:\n",
    "                    S_list=np.vstack((S_list,np.array([1,0])))\n",
    "                    S_list[-1,:]=S_list[-1,:]+S_list[-2,:]\n",
    "                Reward=0                \n",
    "                replay.append([S_list[-2,:],a,Reward,S_list[-1,:]])\n",
    "    else:\n",
    "        S_list=S_0\n",
    "        i=0\n",
    "        while i<max_toss:\n",
    "            if i==0:\n",
    "                a,_=e_greedy(S_list,e=e)\n",
    "            else:\n",
    "                a,_=e_greedy(S_list[-1,:],e=e)\n",
    "            #print(a)\n",
    "            i=i+1\n",
    "            if a!=1:\n",
    "                if a==coin:\n",
    "                    Reward=R_plus/max((len(S_list)-1),1)\n",
    "                else:\n",
    "                    Reward=-R_minus/max((len(S_list)-1),1)\n",
    "                if S_list.ndim==1:\n",
    "                    replay.append([S_list,a,Reward,S_list])\n",
    "                else:\n",
    "                    replay.append([S_list[-1,:],a,Reward,S_list[-1,:]])  \n",
    "                break\n",
    "            else:\n",
    "                #print(S_list)\n",
    "                if np.random.rand(1)<1-f:\n",
    "                    S_list=np.vstack((S_list,np.array([1,0])))\n",
    "                    S_list[-1,:]=S_list[-1,:]+S_list[-2,:]\n",
    "                else:\n",
    "                    S_list=np.vstack((S_list,np.array([0,1])))\n",
    "                    S_list[-1,:]=S_list[-1,:]+S_list[-2,:]\n",
    "                Reward=0\n",
    "                replay.append([S_list[-2,:],a,Reward,S_list[-1,:]])\n",
    "    return replay,S_list\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "\nFound no NVIDIA driver on your system. Please check that you\nhave an NVIDIA GPU and installed a driver from\nhttp://www.nvidia.com/Download/index.aspx",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-4bc3b109a3a7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msetup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-1116b112a1ed>\u001b[0m in \u001b[0;36msetup\u001b[1;34m(lr)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msetup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrent_device\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mQ_net\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRMSprop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\torch\\cuda\\__init__.py\u001b[0m in \u001b[0;36mcurrent_device\u001b[1;34m()\u001b[0m\n\u001b[0;32m    365\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcurrent_device\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m     \u001b[1;34mr\"\"\"Returns the index of a currently selected device.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 367\u001b[1;33m     \u001b[0m_lazy_init\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    368\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cuda_getDevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\torch\\cuda\\__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    176\u001b[0m         raise RuntimeError(\n\u001b[0;32m    177\u001b[0m             \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\n\u001b[1;32m--> 178\u001b[1;33m     \u001b[0m_check_driver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    179\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[0m_cudart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_load_cudart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\torch\\cuda\\__init__.py\u001b[0m in \u001b[0;36m_check_driver\u001b[1;34m()\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[0mFound\u001b[0m \u001b[0mno\u001b[0m \u001b[0mNVIDIA\u001b[0m \u001b[0mdriver\u001b[0m \u001b[0mon\u001b[0m \u001b[0myour\u001b[0m \u001b[0msystem\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mPlease\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0mthat\u001b[0m \u001b[0myou\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[0mhave\u001b[0m \u001b[0man\u001b[0m \u001b[0mNVIDIA\u001b[0m \u001b[0mGPU\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0minstalled\u001b[0m \u001b[0ma\u001b[0m \u001b[0mdriver\u001b[0m \u001b[1;32mfrom\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m http://www.nvidia.com/Download/index.aspx\"\"\")\n\u001b[0m\u001b[0;32m    100\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m             \u001b[1;31m# TODO: directly link to the alternative bin that needs install\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: \nFound no NVIDIA driver on your system. Please check that you\nhave an NVIDIA GPU and installed a driver from\nhttp://www.nvidia.com/Download/index.aspx"
     ]
    }
   ],
   "source": [
    "device, model, optimizer=setup()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=20000\n",
    "for epoch in tqdm(range(N)):\n",
    "    replay,_=Environment(e=0.3-0.1/(N-epoch))\n",
    "    epoch_losses = train_epoch(model, device, replay, optimizer)\n",
    "    if epoch%100==0:\n",
    "        print(f\"Average loss in epoch {epoch}: {np.mean(epoch_losses):.5f}\")\n",
    "        a_2,_=e_greedy([10,0],e=0)\n",
    "        a_3,_=e_greedy([0,10],e=0)\n",
    "        print(a_2.item(),a_3.item())\n",
    "        if np.mean(epoch_losses)<=0.001 and (a_2.item()==2.0 and a_3.item()==3.0):\n",
    "            print('Yeah!')\n",
    "            torch.save(model, \"/home/yucheng/Desktop/coins/Torch_DQN_for_RLcoin/models/3_layer_MLP_\"+str(epoch)+\".pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ep=0.33333\n",
    "n=2\n",
    "model=torch.load(\"/home/yucheng/Desktop/coins/Torch_DQN_for_RLcoin/models/3_layer_MLP_\"+str(ep)+\".pt\")\n",
    "evaluate(d=12)\n",
    "#3 is [0,1], 2 is [1,0] \n",
    "print(\"No.\",ep+N*n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R=list()\n",
    "for i in tqdm(range(1000)):\n",
    "    replay,S_list=Environment(e=0)\n",
    "    r=replay[-1]\n",
    "    R.append(r[2])\n",
    "print(\"Evaluated Average Reward from Greedy policy of the Q net \",np.mean(R))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
